{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc8ac67-d643-4343-8d0c-1b5596947490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EXTRA_JARS = [\n",
    "    \"force-partner-api-40.0.0.jar\",\n",
    "    \"force-wsc-40.0.0.jar\",\n",
    "    \"salesforce-wave-api-1.0.9.jar\",\n",
    "    \"spark-salesforce_2.11-1.1.1.jar\",\n",
    "]\n",
    "\n",
    "# $ wget https://repo1.maven.org/maven2/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.10.3/jackson-dataformat-xml-2.10.3.jar\n",
    "# $ wget https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.10.3/jackson-core-2.10.3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed0e730-0676-4b88-b196-e4ace1976721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.jars.packages': 'com.force.api:force-partner-api:40.0.0,com.force.api:force-wsc:40.0.0,com.springml:salesforce-wave-api:1.0.9,com.springml:spark-salesforce_2.11:1.1.1,com.fasterxml.jackson.core:jackson-core:2.10.3,com.fasterxml.jackson.dataformat:jackson-dataformat-xml:2.10.3'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.jars.packages\": \"com.force.api:force-partner-api:40.0.0,com.force.api:force-wsc:40.0.0,com.springml:salesforce-wave-api:1.0.9,com.springml:spark-salesforce_2.11:1.1.1,com.fasterxml.jackson.core:jackson-core:2.10.3,com.fasterxml.jackson.dataformat:jackson-dataformat-xml:2.10.3\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46bc842d-bf39-490f-8ded-5b76c615401d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "sequence item 0: expected str instance, collections.OrderedDict found\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 52, in create_select_star_soql_stmt\n",
      "  File \"<stdin>\", line 40, in make_select_star_soql_stmt\n",
      "TypeError: sequence item 0: expected str instance, collections.OrderedDict found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "username = \"eric.russia97@gmail.com\"\n",
    "password = \"Ozg0&WgLb6jTsg7\"\n",
    "\n",
    "# get this here: https://docs.idalko.com/exalate/display/ED/Salesforce%3A+How+to+generate+a+security+token\n",
    "security_token = \"lVqxLRwIFZsyVFLRYlT4FvSwf\"\n",
    "\n",
    "password_with_token = password + security_token\n",
    "\n",
    "# username = \"bob\"\n",
    "# password_with_token = \"bobXXXX\"\n",
    "\n",
    "\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "from typing import List, OrderedDict\n",
    "from simple_salesforce import Salesforce, SFType\n",
    "\n",
    "def fetch_all_salesforce_object_fields(username: str, password: str, security_token: str, obj_name: str):\n",
    "    sf = Salesforce(\n",
    "        username=username,\n",
    "        password=password,\n",
    "        security_token=security_token\n",
    "    )\n",
    "\n",
    "    sf_obj: SFType = getattr(sf, obj_name)\n",
    "    sf_description_odict: OrderedDict = sf_obj.describe()\n",
    "    sf_fields = sf_description_odict[\"fields\"]\n",
    "    \n",
    "    print(sf_fields)\n",
    "    \n",
    "#     fields: List[str] = list(sf_fields)\n",
    "\n",
    "    return fields\n",
    "\n",
    "def make_select_star_soql_stmt(obj_name: str, fields: List[str]) -> str:\n",
    "    field_selector_stmt = \", \".join(fields)\n",
    "    return f\"SELECT {field_selector_stmt} FROM {obj_name}\"\n",
    "\n",
    "def create_select_star_soql_stmt(username: str, password: str, security_token: str, obj_name: str):\n",
    "    fields: List[str] = fetch_all_salesforce_object_fields(\n",
    "        username=username,\n",
    "        password=password,\n",
    "        security_token=security_token,\n",
    "        obj_name=obj_name,\n",
    "    )\n",
    "    stmt: str = make_select_star_soql_stmt(\n",
    "        fields=fields,\n",
    "        obj_name=obj_name,\n",
    "    )\n",
    "    return stmt\n",
    "\n",
    "  \n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "\n",
    "\n",
    "select_star_soql_stmt = create_select_star_soql_stmt(\n",
    "    username=username,\n",
    "    password=password,\n",
    "    security_token=security_token,\n",
    "    obj_name=\"Account\",\n",
    ") + \" LIMIT 100\"\n",
    "\n",
    "print(\"Submitting query:\")\n",
    "print(select_star_soql_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc1e51e5-804b-4dc7-a81e-d0c2c9996d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "An error occurred while calling o207.load.\n",
      ": java.lang.Exception: Accessing https://rootski-dev-ed.my.salesforce.com/services/data/v36.0/query?q=SELECT%20actionOverrides,%20activateable,%20associateEntityType,%20associateParentEntity,%20childRelationships,%20compactLayoutable,%20createable,%20custom,%20customSetting,%20deepCloneable,%20defaultImplementation,%20deletable,%20deprecatedAndHidden,%20extendedBy,%20extendsInterfaces,%20feedEnabled,%20fields,%20hasSubtypes,%20implementedBy,%20implementsInterfaces,%20isInterface,%20isSubtype,%20keyPrefix,%20label,%20labelPlural,%20layoutable,%20listviewable,%20lookupLayoutable,%20mergeable,%20mruEnabled,%20name,%20namedLayoutInfos,%20networkScopeFieldName,%20queryable,%20recordTypeInfos,%20replicateable,%20retrieveable,%20searchLayoutable,%20searchable,%20sobjectDescribeOption,%20supportedScopes,%20triggerable,%20undeletable,%20updateable,%20urls%20FROM%20Account%20LIMIT%20100 failed. Status 400. Reason Bad Request \n",
      " Error from server [{\"message\":\"\\nextendsInterfaces, feedEnabled, fields, hasSubtypes, implementedBy, implementsInterfaces\\n                                     ^\\nERROR at Row:1:Column:276\\nunexpected token: ','\",\"errorCode\":\"MALFORMED_QUERY\"}]\n",
      "\tat com.springml.salesforce.wave.util.HTTPHelper.execute(HTTPHelper.java:118)\n",
      "\tat com.springml.salesforce.wave.util.HTTPHelper.get(HTTPHelper.java:91)\n",
      "\tat com.springml.salesforce.wave.util.HTTPHelper.get(HTTPHelper.java:95)\n",
      "\tat com.springml.salesforce.wave.impl.ForceAPIImpl.query(ForceAPIImpl.java:138)\n",
      "\tat com.springml.salesforce.wave.impl.ForceAPIImpl.query(ForceAPIImpl.java:37)\n",
      "\tat com.springml.spark.salesforce.DatasetRelation.querySF(DatasetRelation.scala:105)\n",
      "\tat com.springml.spark.salesforce.DatasetRelation.read(DatasetRelation.scala:47)\n",
      "\tat com.springml.spark.salesforce.DatasetRelation.<init>(DatasetRelation.scala:39)\n",
      "\tat com.springml.spark.salesforce.DefaultSource.createRelation(DefaultSource.scala:99)\n",
      "\tat com.springml.spark.salesforce.DefaultSource.createRelation(DefaultSource.scala:50)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:318)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:167)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/glue_user/spark/python/pyspark/sql/readwriter.py\", line 172, in load\n",
      "    return self._df(self._jreader.load())\n",
      "  File \"/home/glue_user/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/glue_user/spark/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/glue_user/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o207.load.\n",
      ": java.lang.Exception: Accessing https://rootski-dev-ed.my.salesforce.com/services/data/v36.0/query?q=SELECT%20actionOverrides,%20activateable,%20associateEntityType,%20associateParentEntity,%20childRelationships,%20compactLayoutable,%20createable,%20custom,%20customSetting,%20deepCloneable,%20defaultImplementation,%20deletable,%20deprecatedAndHidden,%20extendedBy,%20extendsInterfaces,%20feedEnabled,%20fields,%20hasSubtypes,%20implementedBy,%20implementsInterfaces,%20isInterface,%20isSubtype,%20keyPrefix,%20label,%20labelPlural,%20layoutable,%20listviewable,%20lookupLayoutable,%20mergeable,%20mruEnabled,%20name,%20namedLayoutInfos,%20networkScopeFieldName,%20queryable,%20recordTypeInfos,%20replicateable,%20retrieveable,%20searchLayoutable,%20searchable,%20sobjectDescribeOption,%20supportedScopes,%20triggerable,%20undeletable,%20updateable,%20urls%20FROM%20Account%20LIMIT%20100 failed. Status 400. Reason Bad Request \n",
      " Error from server [{\"message\":\"\\nextendsInterfaces, feedEnabled, fields, hasSubtypes, implementedBy, implementsInterfaces\\n                                     ^\\nERROR at Row:1:Column:276\\nunexpected token: ','\",\"errorCode\":\"MALFORMED_QUERY\"}]\n",
      "\tat com.springml.salesforce.wave.util.HTTPHelper.execute(HTTPHelper.java:118)\n",
      "\tat com.springml.salesforce.wave.util.HTTPHelper.get(HTTPHelper.java:91)\n",
      "\tat com.springml.salesforce.wave.util.HTTPHelper.get(HTTPHelper.java:95)\n",
      "\tat com.springml.salesforce.wave.impl.ForceAPIImpl.query(ForceAPIImpl.java:138)\n",
      "\tat com.springml.salesforce.wave.impl.ForceAPIImpl.query(ForceAPIImpl.java:37)\n",
      "\tat com.springml.spark.salesforce.DatasetRelation.querySF(DatasetRelation.scala:105)\n",
      "\tat com.springml.spark.salesforce.DatasetRelation.read(DatasetRelation.scala:47)\n",
      "\tat com.springml.spark.salesforce.DatasetRelation.<init>(DatasetRelation.scala:39)\n",
      "\tat com.springml.spark.salesforce.DefaultSource.createRelation(DefaultSource.scala:99)\n",
      "\tat com.springml.spark.salesforce.DefaultSource.createRelation(DefaultSource.scala:50)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:318)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:167)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark\n",
    "        .read\n",
    "        .format(\"com.springml.spark.salesforce\")\n",
    "        .option(\"username\", username)\n",
    "        .option(\"password\", password_with_token)\n",
    "        .option(\"soql\", select_star_soql_stmt)\n",
    "#         .option(\"bulk\", True)\n",
    "        .load()\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4728d7-9e7e-4ead-9814-7561d5e900e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue Spark - Local (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
